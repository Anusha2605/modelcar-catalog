inferenceService:
  storage:
    mode: uri
    storageUri: oci://quay.io/redhat-ai-services/modelcar-catalog:llama-3.2-3b-instruct
